<!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Naive Bayes Classifier Calculator &amp; Visual Guide</title>
  <meta name="description" content="Interactive naive Bayes classifier calculator for discrete features. Enter priors and conditional probabilities, compute posterior class probabilities, and see step-by-step Bayes rule explanations.">
  <link rel="canonical" href="https://calcdomain.com/naive-bayes">

  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="manifest" href="/site.webmanifest">

  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap" rel="stylesheet">
  <style>
    body { font-family: 'Inter', sans-serif; }
    .card-hover { transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out; }
    .card-hover:hover { transform: translateY(-5px); box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05); }
    .prose { max-width: 65ch; margin-left: auto; margin-right: auto; }
    .prose h2 { font-size: 1.5rem; font-weight: 600; margin-top: 2rem; margin-bottom: 1rem; }
    .prose h3 { font-size: 1.25rem; font-weight: 600; margin-top: 1.5rem; margin-bottom: 0.5rem; }
    .prose p { margin-bottom: 1rem; line-height: 1.6; }
    .prose ul, .prose ol { margin-left: 1.5rem; margin-bottom: 1rem; }
    .prose li { margin-bottom: 0.5rem; }
    .formula-box { background: #f3f4f6; border: 1px solid #d1d5db; border-radius: 8px; padding: 1rem; overflow-x: auto; margin: 1rem 0; }
    .badge-pill {
      display: inline-flex;
      align-items: center;
      border-radius: 9999px;
      padding: 0.25rem 0.75rem;
      font-size: 0.75rem;
    }
    .nb-table th, .nb-table td {
      border: 1px solid #e5e7eb;
      padding: 0.5rem;
      font-size: 0.75rem;
    }
    .nb-table th {
      background-color: #f9fafb;
      font-weight: 600;
    }
    .nb-chip-active {
      background-color: #2563eb;
      color: white;
      border-color: #2563eb;
    }
  </style>

  <!-- HEAD_SCRIPTS_E_META -->
  <!-- Google tag (gtag.js) -->
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-7MB5V1LZRN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-7MB5V1LZRN');
  </script>

  <meta name="google-site-verification" content="_tiTZ9ivAdtXcAS9CMnTNJ549Sg39WVqP_ZFbWgglNA">

  <script src="https://cmp.gatekeeperconsent.com/min.js" data-cfasync="false"></script>
  <script src="https://the.gatekeeperconsent.com/cmp.min.js" data-cfasync="false"></script>

  <script async="" src="//www.ezojs.com/ezoic/sa.min.js"></script>
  <script>
    window.ezstandalone = window.ezstandalone || {};
    ezstandalone.cmd = ezstandalone.cmd || [];
  </script>

  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": "WebSite",
      "@id": "https://calcdomain.com/#website",
      "url": "https://calcdomain.com/",
      "name": "CalcDomain",
      "inLanguage": "en"
    },
    {
      "@type": "WebPage",
      "@id": "https://calcdomain.com/naive-bayes#webpage",
      "url": "https://calcdomain.com/naive-bayes",
      "name": "Naive Bayes Classifier Calculator & Visual Guide",
      "description": "Interactive naive Bayes classifier calculator for discrete features. Enter priors and conditional probabilities, compute posterior class probabilities, and see step-by-step Bayes rule explanations.",
      "inLanguage": "en",
      "isPartOf": {
        "@id": "https://calcdomain.com/#website"
      },
      "breadcrumb": {
        "@id": "https://calcdomain.com/naive-bayes#breadcrumb"
      }
    },
    {
      "@type": "BreadcrumbList",
      "@id": "https://calcdomain.com/naive-bayes#breadcrumb",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://calcdomain.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "General",
          "item": "https://calcdomain.com/categories/general"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "Miscellaneous",
          "item": "https://calcdomain.com/subcategories/miscellaneous"
        }
      ]
    },
    {
      "@type": "FAQPage",
      "@id": "https://calcdomain.com/naive-bayes#faq",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "What is a naive Bayes classifier?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "A naive Bayes classifier is a probabilistic model based on Bayes’ theorem that assigns a class label to an observation by combining a prior probability for each class with the likelihood of the observed features under that class. The 'naive' assumption is that features are conditionally independent given the class, which simplifies the likelihood into a product of one-dimensional terms."
          }
        },
        {
          "@type": "Question",
          "name": "Why is it called 'naive' Bayes?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "It is called 'naive' because the classifier assumes that features are conditionally independent given the class. This assumption is rarely exactly true in real data, but in practice the model often performs surprisingly well, especially for high-dimensional and sparse problems such as text classification."
          }
        },
        {
          "@type": "Question",
          "name": "When should I use a naive Bayes classifier?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Naive Bayes is well suited to problems with many features that can be treated as conditionally independent given the class, such as spam filtering, document categorization and simple medical triage models. It is fast to train and evaluate, works well with relatively small samples and can be used as a baseline model against which more complex methods are compared."
          }
        },
        {
          "@type": "Question",
          "name": "What is the difference between prior, likelihood and posterior in naive Bayes?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "The prior P(Ck) reflects how likely class Ck is before observing any features. The likelihood P(x|Ck) measures how compatible the observed features x are with class Ck. The posterior P(Ck|x) combines these via Bayes’ theorem and is proportional to P(Ck)P(x|Ck); it represents how likely the class is after seeing the features."
          }
        }
      ]
    },
    {
      "@type": "HowTo",
      "@id": "https://calcdomain.com/naive-bayes#howto",
      "name": "How to use the naive Bayes classifier calculator",
      "inLanguage": "en",
      "step": [
        {
          "@type": "HowToStep",
          "position": 1,
          "name": "Choose classes and features",
          "itemListElement": [
            {
              "@type": "HowToDirection",
              "text": "Set the number of classes and features, and optionally rename the classes and features to match your problem."
            }
          ]
        },
        {
          "@type": "HowToStep",
          "position": 2,
          "name": "Enter priors and conditional probabilities",
          "itemListElement": [
            {
              "@type": "HowToDirection",
              "text": "Provide a prior probability for each class and conditional probabilities for each binary feature being present given each class. If you leave priors empty or all zero, equal priors will be used."
            }
          ]
        },
        {
          "@type": "HowToStep",
          "position": 3,
          "name": "Specify the observed features",
          "itemListElement": [
            {
              "@type": "HowToDirection",
              "text": "Indicate which features are present or absent in the observation you want to classify using the feature toggles."
            }
          ]
        },
        {
          "@type": "HowToStep",
          "@id": "https://calcdomain.com/naive-bayes#howto-step4",
          "position": 4,
          "name": "Compute and interpret the posterior",
          "itemListElement": [
            {
              "@type": "HowToDirection",
              "text": "Click the Classify button to compute the unnormalized scores and normalized posterior probabilities for each class. The calculator shows which class has the highest posterior and provides a short interpretation."
            }
          ]
        }
      ]
    }
  ]
}
</script>

<style>
/* AUDIT_SPINE_CSS */
.auditspine-note{
  border:1px solid #e5e7eb;
  background:#fff;
  border-radius:12px;
  padding:12px;
  color:#475569;
  font-size:13px;
  line-height:1.5;
}
.auditspine-mono{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
.auditspine-changelog{
  border:1px solid #e5e7eb;
  background:#fff;
  border-left:5px solid #334155;
  border-radius:12px;
  padding:12px;
  font-size:13px;
  color:#475569;
}
.auditspine-formula{
  margin:10px 0;
  background:#0b1220;
  color:#e5e7eb;
  border-radius:12px;
  padding:12px;
  border:1px solid rgba(255,255,255,.12);
  overflow-x:auto;
}
.auditspine-formula pre{margin:8px 0 0; white-space:pre-wrap;}
.auditspine-hr{border:none; border-top:1px solid #e5e7eb; margin:18px 0;}
.auditspine-badge{
  display:inline-block;
  padding:4px 10px;
  border-radius:999px;
  font-size:12px;
  font-weight:600;
  border:1px solid #e5e7eb;
  background:#f8fafc;
  color:#0f172a;
}
.auditspine-badge-warn{
  background:#fff7ed;
  border-color:#fed7aa;
  color:#9a3412;
}
</style>
</head>
<body class="bg-gray-50 text-gray-800">

  <!-- BODY_SCRIPTS_INIZIO -->
  <script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9476637732224939" crossorigin="anonymous"></script>

  <header class="bg-white shadow-sm sticky top-0 z-50">
    <nav class="container mx-auto px-4 lg:px-6 py-4" aria-label="Primary">
      <div class="flex justify-between items-center">
        <a href="https://calcdomain.com" class="text-2xl font-bold text-blue-600">CalcDomain</a>
        <div class="w-full max-w-md hidden md:block mx-8">
          <div class="relative">
            <input type="search" id="search-input" placeholder="Search for a calculator..." class="w-full py-2 px-4 pr-10 border border-gray-300 rounded-full focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent" autocomplete="off">
            <svg class="w-5 h-5 absolute right-4 top-1/2 -translate-y-1/2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg>
            <div id="search-results" class="absolute top-full left-0 right-0 bg-white shadow-lg rounded-lg mt-2 max-h-96 overflow-y-auto z-50 hidden border border-gray-200"></div>
          </div>
        </div>
        <div class="hidden md:flex items-center space-x-6">
          <a href="https://calcdomain.com/search" class="text-gray-700 hover:text-blue-600 transition-colors">Advanced Search</a>
          <a href="https://calcdomain.com/#categories" class="text-gray-700 hover:text-blue-600 transition-colors">Categories</a>
        </div>
        <button id="mobile-menu-toggle" class="md:hidden p-2" aria-controls="mobile-menu" aria-expanded="false" aria-label="Open menu" type="button">
          <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg>
        </button>
      </div>
      <nav id="mobile-menu" class="md:hidden mt-4 hidden" aria-label="Mobile menu" role="navigation">
        <div class="mb-4">
          <div class="relative">
            <input type="search" id="mobile-search-input" placeholder="Search calculators..." class="w-full py-3 px-4 pr-10 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500">
            <svg class="w-5 h-5 absolute right-4 top-1/2 -translate-y-1/2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg>
          </div>
        </div>
        <div class="space-y-2">
          <a href="https://calcdomain.com/search" class="block py-2 text-gray-700 hover:text-blue-600">Advanced Search</a>
          <a href="https://calcdomain.com/#categories" class="block py-2 text-gray-700 hover:text-blue-600">Categories</a>
        </div>
      </nav>
    </nav>
  </header>

  <div class="container mx-auto px-4 py-8">

    <nav class="text-sm mb-4 text-gray-600" aria-label="Breadcrumbs"><a href="https://calcdomain.com" class="hover:text-blue-600">Home</a> &raquo; <a href="https://calcdomain.com/categories/general" class="hover:text-blue-600">General</a> &raquo; <a href="https://calcdomain.com/subcategories/miscellaneous" class="hover:text-blue-600">Miscellaneous</a></nav>

    <div class="flex flex-col lg:flex-row gap-8">

      <main class="w-full lg:w-2/3">
        <div class="bg-white p-6 rounded-lg shadow-md">

          <header class="mb-6 border-b border-gray-100 pb-4">
            <h1 class="text-2xl md:text-3xl font-bold text-gray-900 mb-2">
              Naive Bayes Classifier Calculator &amp; Visual Guide
            </h1>
            <p class="text-gray-700">
              Build a simple <strong>naive Bayes classifier</strong> with discrete, binary features:
              set class priors and conditional probabilities, classify an observation, and see the
              posterior probabilities and Bayes rule steps.
            </p>
            <div class="mt-4 flex flex-wrap gap-2 text-xs text-gray-500">
              <span class="badge-pill bg-gray-100 text-gray-800">
                Naive Bayes · Bayes’ theorem · Posterior probabilities
              </span>
              <span class="badge-pill bg-gray-100 text-gray-800">
                Discrete/Bernoulli features · Machine learning
              </span>
            </div>
          </header>

          <!-- CONFIGURATION SECTION -->
          <section aria-labelledby="nb-config-heading" class="mb-8">
            <h2 id="nb-config-heading" class="text-xl font-semibold mb-3">
              1. Configure the naive Bayes model structure
            </h2>
            <p class="text-sm text-gray-700 mb-3">
              Choose how many <strong>classes</strong> and <strong>binary features</strong> your model has.
              Features are treated as present/absent; for each class you will specify
              \(P(\text{feature present} \mid \text{class})\).
            </p>

            <div class="grid md:grid-cols-3 gap-4 mb-4">
              <div>
                <label for="nb-num-classes" class="block text-sm font-medium text-gray-700 mb-1">
                  Number of classes
                </label>
                <select id="nb-num-classes" class="w-full border border-gray-300 rounded-md px-3 py-1.5 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500">
                  <option value="2">2 classes</option>
                  <option value="3" selected="">3 classes</option>
                  <option value="4">4 classes</option>
                </select>
                <p class="text-[11px] text-gray-500 mt-1">
                  E.g. spam vs not spam, positive/neutral/negative sentiment, etc.
                </p>
              </div>
              <div>
                <label for="nb-num-features" class="block text-sm font-medium text-gray-700 mb-1">
                  Number of features
                </label>
                <select id="nb-num-features" class="w-full border border-gray-300 rounded-md px-3 py-1.5 text-sm focus:outline-none focus:ring-2 focus:ring-blue-500">
                  <option value="1">1 feature</option>
                  <option value="2">2 features</option>
                  <option value="3" selected="">3 features</option>
                  <option value="4">4 features</option>
                  <option value="5">5 features</option>
                </select>
                <p class="text-[11px] text-gray-500 mt-1">
                  Features are binary (present/absent) in this tool.
                </p>
              </div>
              <div>
                <span class="block text-sm font-medium text-gray-700 mb-1">
                  Input mode
                </span>
                <p class="text-xs text-gray-600">
                  This calculator uses <strong>probabilities</strong> as input.
                  To go from counts to probabilities, divide the count with feature present by the
                  total count per class. For sparse data you may want to use Laplace smoothing.
                </p>
              </div>
            </div>

            <div class="flex flex-wrap gap-2">
              <button type="button" id="nb-reset-structure" class="inline-flex items-center px-3 py-1.5 rounded-md bg-white border border-gray-300 text-xs font-medium text-gray-800 hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-offset-1">
                Reset structure
              </button>
              <button type="button" id="nb-load-spam-example" class="inline-flex items-center px-3 py-1.5 rounded-md bg-gray-100 text-xs font-medium text-gray-800 hover:bg-gray-200 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-offset-1">
                Load spam filter example
              </button>
            </div>
          </section>

          <!-- PRIORS & CONDITIONAL PROBABILITIES -->
          <section aria-labelledby="nb-params-heading" class="mb-8">
            <h2 id="nb-params-heading" class="text-xl font-semibold mb-3">
              2. Enter priors and conditional probabilities
            </h2>

            <div id="nb-params-error" class="hidden mb-3 rounded-md bg-red-50 border border-red-200 px-3 py-2 text-sm text-red-700"></div>

            <p class="text-sm text-gray-700 mb-3">
              For each class \(C_k\), enter a prior \(P(C_k)\).
              If you leave all priors 0 or empty, the calculator will assume
              <strong>equal priors</strong>. For each feature \(X_j\) and class \(C_k\),
              enter \(P(X_j = \text{present} \mid C_k)\).
            </p>

            <div class="overflow-x-auto mb-4">
              <table class="nb-table min-w-full text-left align-top">
                <thead>
                  <tr>
                    <th scope="col">Class</th>
                    <th scope="col">Prior P(Class)</th>
                    <th scope="col">Class name</th>
                  </tr>
                </thead>
                <tbody id="nb-prior-body">
                  <!-- Filled by JS -->
                </tbody>
              </table>
            </div>

            <div class="overflow-x-auto mb-2">
              <table class="nb-table min-w-full text-left align-top">
                <thead id="nb-conditional-head">
                  <!-- Filled by JS -->
                </thead>
                <tbody id="nb-conditional-body">
                  <!-- Filled by JS -->
                </tbody>
              </table>
            </div>
            <p class="text-[11px] text-gray-500 mb-2">
              Each cell is \(P(\text{feature present} \mid \text{class})\) in [0, 1].
              The probability of absence is \(1 - p\).
            </p>
            <p class="text-[11px] text-gray-500">
              To avoid zero-probability issues, probabilities of exactly 0 or 1 are internally
              clipped slightly toward the interior of (0, 1) when computing log-likelihoods.
            </p>
          </section>

          <!-- OBSERVATION & CLASSIFICATION -->
          <section aria-labelledby="nb-observation-heading" class="mb-8">
            <h2 id="nb-observation-heading" class="text-xl font-semibold mb-3">
              3. Describe the observation to classify
            </h2>

            <p class="text-sm text-gray-700 mb-3">
              Use the toggles to indicate which features are <strong>present</strong> in the observation.
              Features left off are treated as <strong>absent</strong>.
            </p>

            <div id="nb-observation-features" class="flex flex-wrap gap-2 mb-4">
              <!-- Feature chips built by JS -->
            </div>

            <div class="flex flex-wrap items-center gap-2 mb-4">
              <button type="button" id="nb-classify" class="inline-flex items-center px-4 py-2 rounded-md bg-blue-600 text-white text-sm font-medium hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-1">
                Classify observation
              </button>
              <button type="button" id="nb-clear-observation" class="inline-flex items-center px-3 py-1.5 rounded-md bg-white border border-gray-300 text-xs font-medium text-gray-800 hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-gray-400 focus:ring-offset-1">
                Clear features
              </button>
            </div>

            <div id="nb-result-error" class="hidden mb-3 rounded-md bg-red-50 border border-red-200 px-3 py-2 text-sm text-red-700"></div>

            <div id="nb-results-container" class="hidden">
              <h3 class="text-lg font-semibold mb-2">Posterior probabilities by class</h3>
              <div class="overflow-x-auto mb-3">
                <table class="nb-table min-w-full text-left align-top">
                  <thead>
                    <tr>
                      <th scope="col">Class</th>
                      <th scope="col">Prior P(C)</th>
                      <th scope="col">Log score (unnormalized)</th>
                      <th scope="col">Posterior P(C | x)</th>
                    </tr>
                  </thead>
                  <tbody id="nb-results-body">
                    <!-- Filled by JS -->
                  </tbody>
                </table>
              </div>
              <p id="nb-results-interpretation" class="text-sm text-gray-700 mb-2"></p>
              <p class="text-xs text-gray-600">
                Scores are computed as
                \( \log P(C_k) + \sum_j \log P(x_j \mid C_k) \)
                under the naive independence assumption, then exponentiated and normalized so posteriors
                sum to 1.
              </p>
            </div>
          </section>

          <!-- EXPLANATORY CONTENT -->
          <section class="prose">
            <h2>Naive Bayes classifier in a nutshell</h2>
            <p>
              A <strong>naive Bayes classifier</strong> uses Bayes’ theorem to assign a class label to an observation.
              For a discrete feature vector \(x = (x_1, \dots, x_d)\) and classes \(C_1, \dots, C_K\), the classifier
              predicts the class with the largest posterior probability
              \[
                P(C_k \mid x) = \frac{P(C_k) P(x \mid C_k)}{P(x)}.
              \]
              Since \(P(x)\) is the same for every class, we only need to compare
              \[
                P(C_k \mid x) \propto P(C_k) P(x \mid C_k).
              \]
            </p>

            <h2>The “naive” conditional independence assumption</h2>
            <p>
              The difficult part in high dimensions is modelling the joint likelihood \(P(x \mid C_k)\).
              Naive Bayes makes a simplifying – and often unrealistic – assumption:
              <strong>conditional independence</strong> of features given the class:
            </p>
            <div class="formula-box">
              \[
                P(x \mid C_k) = P(x_1, \dots, x_d \mid C_k)
                \approx \prod_{j=1}^{d} P(x_j \mid C_k).
              \]
            </div>
            <p>
              For <strong>binary features</strong> (present/absent) this becomes especially simple. If we denote
              \(X_j \in \{0,1\}\) and write
              \[
                \theta_{jk} = P(X_j = 1 \mid C_k),
              \]
              then
              \[
                P(x_j \mid C_k) =
                \begin{cases}
                  \theta_{jk}, &amp; \text{if } x_j = 1,\\[4pt]
                  1 - \theta_{jk}, &amp; \text{if } x_j = 0.
                \end{cases}
              \]
            </p>

            <h2>Posterior computation in this calculator</h2>
            <p>
              The calculator computes an unnormalized log-score for each class:
            </p>
            <div class="formula-box">
              \[
                s_k = \log P(C_k) + \sum_{j=1}^{d} \log P(x_j \mid C_k).
              \]
            </div>
            <p>
              To avoid numerical underflow, we work in log space and then subtract the maximum score before
              exponentiating:
            </p>
            <div class="formula-box">
              \[
                \tilde p_k = \exp(s_k - s_{\max}), \quad
                P(C_k \mid x) = \frac{\tilde p_k}{\sum_{\ell=1}^{K} \tilde p_\ell}.
              \]
            </div>
            <p>
              This yields stable posterior probabilities that sum to 1, even when there are many features.
            </p>

            <h2>From counts to probabilities (training a naive Bayes model)</h2>
            <p>
              In practice, you usually start from a labelled dataset. For a binary feature \(X_j\) and class \(C_k\),
              let:
            </p>
            <ul>
              <li>\(n_{jk}^{(1)}\): number of training examples in class \(C_k\) with feature \(X_j = 1\)</li>
              <li>\(n_{k}\): total number of training examples in class \(C_k\)</li>
            </ul>
            <p>
              A simple estimate of the conditional probability is:
            </p>
            <div class="formula-box">
              \[
                \hat \theta_{jk} = \frac{n_{jk}^{(1)}}{n_k}.
              \]
            </div>
            <p>
              To avoid zero probabilities, many implementations use <strong>Laplace (add-one) smoothing</strong>:
            </p>
            <div class="formula-box">
              \[
                \hat \theta_{jk}^{(\text{Laplace})}
                = \frac{n_{jk}^{(1)} + \alpha}{n_k + 2\alpha},
              \]
              where \(\alpha = 1\) is a common choice for Bernoulli features.
            </div>

            <h2 id="faq-heading">FAQ – naive Bayes classifier</h2>

            <h3>How does naive Bayes compare to logistic regression?</h3>
            <p>
              Both are probabilistic classifiers, but they model different quantities. Naive Bayes models the
              class-conditional likelihoods \(P(x \mid C_k)\) and priors \(P(C_k)\), then uses Bayes’ theorem to obtain
              the posterior. Logistic regression directly models \(P(C_k \mid x)\) using a linear function of x and the
              logistic link. Logistic regression does not assume feature independence but usually requires more data and
              iterative optimization to train.
            </p>

            <h3>What are typical applications of naive Bayes?</h3>
            <p>
              Classic applications include <strong>spam filtering</strong>, <strong>document classification</strong>,
              <strong>sentiment analysis</strong> and simple <strong>medical triage</strong>. Because the model is
              extremely fast to train and to evaluate, it is often used as a baseline for large-scale text and
              recommender systems.
            </p>

            <h3>What are the main limitations of naive Bayes?</h3>
            <p>
              The independence assumption is often violated: correlated features can lead to over-confident
              probabilities. In addition, naive Bayes with simple likelihoods (e.g. Bernoulli or Gaussian) may underfit
              complex class-conditional structures. It is therefore not a universal solution but a strong baseline and a
              good choice when data are limited and interpretability and speed are important.
            </p>

            <h3>Can I use this calculator for continuous features?</h3>
            <p>
              This specific implementation assumes binary features (present/absent). In practice, continuous naive Bayes
              models (e.g. Gaussian naive Bayes) are common: each feature is modelled as a normal distribution conditional
              on the class. To use this calculator with continuous features, you would need to first discretize them into
              binary indicators (for example, high vs low).
            </p>
          </section>

          <!-- JS: UTILITIES & MODEL BUILDING -->
          <script>
            function nbShowError(el, msg) {
              el.textContent = msg;
              el.classList.remove('hidden');
            }
            function nbHideError(el) {
              el.textContent = '';
              el.classList.add('hidden');
            }

            // Build priors and conditional tables and feature chips
            (function () {
              const numClassesSelect = document.getElementById('nb-num-classes');
              const numFeaturesSelect = document.getElementById('nb-num-features');
              const priorBody = document.getElementById('nb-prior-body');
              const condHead = document.getElementById('nb-conditional-head');
              const condBody = document.getElementById('nb-conditional-body');
              const featureChipContainer = document.getElementById('nb-observation-features');

              const paramsError = document.getElementById('nb-params-error');

              const btnResetStructure = document.getElementById('nb-reset-structure');
              const btnSpamExample = document.getElementById('nb-load-spam-example');

              function buildTables() {
                nbHideError(paramsError);

                const K = parseInt(numClassesSelect.value, 10);
                const D = parseInt(numFeaturesSelect.value, 10);

                // Build priors table
                let priorRows = '';
                for (let k = 0; k < K; k++) {
                  const clsId = k + 1;
                  priorRows += `
                    <tr>
                      <td>
                        <span class="inline-flex items-center text-xs font-medium px-2 py-1 rounded-full bg-blue-50 text-blue-700 border border-blue-100">
                          C${clsId}
                        </span>
                      </td>
                      <td>
                        <input
                          type="number"
                          step="any"
                          min="0"
                          max="1"
                          class="w-full border border-gray-300 rounded-md px-2 py-1 text-xs focus:outline-none focus:ring-2 focus:ring-blue-500"
                          data-nb="prior"
                          data-class-index="${k}"
                          placeholder="e.g. 0.5"
                        />
                      </td>
                      <td>
                        <input
                          type="text"
                          class="w-full border border-gray-300 rounded-md px-2 py-1 text-xs focus:outline-none focus:ring-2 focus:ring-blue-500"
                          data-nb="class-name"
                          data-class-index="${k}"
                          value="Class ${clsId}"
                        />
                      </td>
                    </tr>
                  `;
                }
                priorBody.innerHTML = priorRows;

                // Build conditional header
                let headHtml = '<tr><th scope="col">Class</th>';
                for (let j = 0; j < D; j++) {
                  const featId = j + 1;
                  headHtml += `
                    <th scope="col">
                      <div class="flex flex-col">
                        <span>Feature ${featId}</span>
                        <input
                          type="text"
                          class="mt-1 border border-gray-200 rounded-md px-1 py-0.5 text-[11px] focus:outline-none focus:ring-1 focus:ring-blue-500"
                          data-nb="feature-name"
                          data-feature-index="${j}"
                          value="Feature ${featId}"
                        />
                      </div>
                    </th>
                  `;
                }
                headHtml += '</tr>';
                condHead.innerHTML = headHtml;

                // Build conditional body
                let bodyHtml = '';
                for (let k = 0; k < K; k++) {
                  const clsId = k + 1;
                  bodyHtml += `
                    <tr>
                      <td>
                        <span class="inline-flex items-center text-xs font-medium px-2 py-1 rounded-full bg-blue-50 text-blue-700 border border-blue-100">
                          C${clsId}
                        </span>
                      </td>
                  `;
                  for (let j = 0; j < D; j++) {
                    bodyHtml += `
                      <td>
                        <label class="block text-[11px] text-gray-600 mb-0.5">
                          P(present | C${clsId})
                        </label>
                        <input
                          type="number"
                          step="any"
                          min="0"
                          max="1"
                          class="w-full border border-gray-300 rounded-md px-2 py-1 text-xs focus:outline-none focus:ring-2 focus:ring-blue-500"
                          data-nb="cond"
                          data-class-index="${k}"
                          data-feature-index="${j}"
                          placeholder="e.g. 0.8"
                        />
                      </td>
                    `;
                  }
                  bodyHtml += '</tr>';
                }
                condBody.innerHTML = bodyHtml;

                // Build feature chips for observation
                let chipHtml = '';
                for (let j = 0; j < D; j++) {
                  const featId = j + 1;
                  chipHtml += `
                    <button
                      type="button"
                      class="nb-feature-chip inline-flex items-center px-3 py-1.5 rounded-full border border-gray-300 bg-gray-50 text-xs text-gray-800 focus:outline-none focus:ring-2 focus:ring-blue-500"
                      data-feature-index="${j}"
                      aria-pressed="false"
                    >
                      <span class="mr-1">Feature ${featId}</span>
                      <span class="nb-chip-state text-[11px] text-gray-500">(absent)</span>
                    </button>
                  `;
                }
                featureChipContainer.innerHTML = chipHtml;

                // Attach chip toggles
                featureChipContainer.querySelectorAll('.nb-feature-chip').forEach(btn => {
                  btn.addEventListener('click', () => {
                    const pressed = btn.getAttribute('aria-pressed') === 'true';
                    btn.setAttribute('aria-pressed', String(!pressed));
                    const stateSpan = btn.querySelector('.nb-chip-state');
                    if (!pressed) {
                      btn.classList.add('nb-chip-active');
                      stateSpan.textContent = '(present)';
                    } else {
                      btn.classList.remove('nb-chip-active');
                      stateSpan.textContent = '(absent)';
                    }
                  });
                });
              }

              numClassesSelect.addEventListener('change', buildTables);
              numFeaturesSelect.addEventListener('change', buildTables);

              btnResetStructure.addEventListener('click', () => {
                numClassesSelect.value = '3';
                numFeaturesSelect.value = '3';
                buildTables();
              });

              btnSpamExample.addEventListener('click', () => {
                numClassesSelect.value = '2';
                numFeaturesSelect.value = '3';
                buildTables();

                // Priors: spam 0.4, ham 0.6
                const priors = priorBody.querySelectorAll('input[data-nb="prior"]');
                if (priors[0]) priors[0].value = '0.4';
                if (priors[1]) priors[1].value = '0.6';

                // Class names
                const names = priorBody.querySelectorAll('input[data-nb="class-name"]');
                if (names[0]) names[0].value = 'Spam';
                if (names[1]) names[1].value = 'Not spam';

                // Feature names
                const fNames = condHead.querySelectorAll('input[data-nb="feature-name"]');
                if (fNames[0]) fNames[0].value = 'Contains "offer"';
                if (fNames[1]) fNames[1].value = 'Contains "$"';
                if (fNames[2]) fNames[2].value = 'Many exclamation marks';

                // Conditional probabilities: (rough illustrative values)
                const conds = condBody.querySelectorAll('input[data-nb="cond"]');
                conds.forEach(input => {
                  const c = parseInt(input.getAttribute('data-class-index'), 10);
                  const f = parseInt(input.getAttribute('data-feature-index'), 10);
                  let val = 0.5;
                  if (c === 0) { // Spam
                    if (f === 0) val = 0.9;
                    if (f === 1) val = 0.8;
                    if (f === 2) val = 0.7;
                  } else if (c === 1) { // Not spam
                    if (f === 0) val = 0.1;
                    if (f === 1) val = 0.05;
                    if (f === 2) val = 0.1;
                  }
                  input.value = String(val);
                });

                // Pre-select some features as present
                const chips = document.querySelectorAll('.nb-feature-chip');
                chips.forEach((btn, idx) => {
                  const stateSpan = btn.querySelector('.nb-chip-state');
                  if (idx === 0 || idx === 1) {
                    btn.setAttribute('aria-pressed', 'true');
                    btn.classList.add('nb-chip-active');
                    stateSpan.textContent = '(present)';
                  } else {
                    btn.setAttribute('aria-pressed', 'false');
                    btn.classList.remove('nb-chip-active');
                    stateSpan.textContent = '(absent)';
                  }
                });
              });

              // Initial build
              buildTables();
            }());
          </script>

          <!-- JS: CLASSIFICATION LOGIC -->
          <script>
            (function () {
              const priorBody = document.getElementById('nb-prior-body');
              const condHead = document.getElementById('nb-conditional-head');
              const condBody = document.getElementById('nb-conditional-body');
              const featureChipContainer = document.getElementById('nb-observation-features');
              const numClassesSelect = document.getElementById('nb-num-classes');
              const numFeaturesSelect = document.getElementById('nb-num-features');

              const paramsError = document.getElementById('nb-params-error');
              const resultError = document.getElementById('nb-result-error');

              const btnClassify = document.getElementById('nb-classify');
              const btnClearObs = document.getElementById('nb-clear-observation');

              const resultsContainer = document.getElementById('nb-results-container');
              const resultsBody = document.getElementById('nb-results-body');
              const resultsInterpretation = document.getElementById('nb-results-interpretation');

              function clipProb(p) {
                const eps = 1e-9;
                if (p <= 0) return eps;
                if (p >= 1) return 1 - eps;
                return p;
              }

              function getModelAndObservation() {
                nbHideError(paramsError);
                nbHideError(resultError);

                const K = parseInt(numClassesSelect.value, 10);
                const D = parseInt(numFeaturesSelect.value, 10);

                const priors = new Array(K).fill(0);
                const classNames = new Array(K);
                const cond = new Array(K);
                const featureNames = new Array(D);

                // Get class names & priors
                const priorInputs = priorBody.querySelectorAll('input[data-nb="prior"]');
                const nameInputs = priorBody.querySelectorAll('input[data-nb="class-name"]');
                if (priorInputs.length !== K || nameInputs.length !== K) {
                  nbShowError(paramsError, 'Internal error: mismatch in number of classes.');
                  return null;
                }

                let sumPriors = 0;
                let allZeroOrEmpty = true;
                for (let k = 0; k < K; k++) {
                  const pStr = priorInputs[k].value.trim();
                  let p = parseFloat(pStr);
                  if (!isFinite(p)) p = 0;
                  if (p < 0) {
                    nbShowError(paramsError, 'Prior probabilities P(C) must be ≥ 0.');
                    return null;
                  }
                  priors[k] = p;
                  if (p > 0) allZeroOrEmpty = false;
                  sumPriors += p;
                  const nm = nameInputs[k].value.trim();
                  classNames[k] = nm || ('Class ' + (k + 1));
                }

                if (allZeroOrEmpty) {
                  // Equal priors
                  for (let k = 0; k < K; k++) priors[k] = 1 / K;
                  sumPriors = 1;
                } else if (sumPriors <= 0) {
                  nbShowError(paramsError, 'Sum of prior probabilities must be > 0 if any are specified.');
                  return null;
                } else {
                  // Normalize priors
                  for (let k = 0; k < K; k++) priors[k] /= sumPriors;
                }

                // Feature names
                const fNameInputs = condHead.querySelectorAll('input[data-nb="feature-name"]');
                if (fNameInputs.length !== D) {
                  nbShowError(paramsError, 'Internal error: mismatch in number of features.');
                  return null;
                }
                for (let j = 0; j < D; j++) {
                  const nm = fNameInputs[j].value.trim();
                  featureNames[j] = nm || ('Feature ' + (j + 1));
                }

                // Conditional probabilities
                const condInputs = condBody.querySelectorAll('input[data-nb="cond"]');
                if (condInputs.length !== K * D) {
                  nbShowError(paramsError, 'Internal error: mismatch in conditional probability grid.');
                  return null;
                }
                for (let k = 0; k < K; k++) {
                  cond[k] = new Array(D);
                }
                for (let idx = 0; idx < condInputs.length; idx++) {
                  const input = condInputs[idx];
                  const k = parseInt(input.getAttribute('data-class-index'), 10);
                  const j = parseInt(input.getAttribute('data-feature-index'), 10);
                  let pStr = input.value.trim();
                  let p = parseFloat(pStr);
                  if (!isFinite(p)) {
                    nbShowError(paramsError, 'All conditional probabilities must be numbers between 0 and 1.');
                    return null;
                  }
                  if (p < 0 || p > 1) {
                    nbShowError(paramsError, 'Conditional probabilities must be in [0, 1].');
                    return null;
                  }
                  cond[k][j] = p;
                }

                // Observation feature presence
                const chips = featureChipContainer.querySelectorAll('.nb-feature-chip');
                const obs = new Array(D).fill(0);
                chips.forEach(btn => {
                  const j = parseInt(btn.getAttribute('data-feature-index'), 10);
                  const isPresent = btn.getAttribute('aria-pressed') === 'true';
                  obs[j] = isPresent ? 1 : 0;
                });

                return { K, D, priors, classNames, cond, featureNames, obs };
              }

              function classify() {
                const model = getModelAndObservation();
                if (!model) {
                  resultsContainer.classList.add('hidden');
                  return;
                }

                const { K, D, priors, classNames, cond, featureNames, obs } = model;
                const logScores = new Array(K);
                let maxLog = -Infinity;

                for (let k = 0; k < K; k++) {
                  let logp = Math.log(clipProb(priors[k]));
                  for (let j = 0; j < D; j++) {
                    const p1 = clipProb(cond[k][j]);
                    const pj = obs[j] === 1 ? p1 : (1 - p1);
                    logp += Math.log(clipProb(pj));
                  }
                  logScores[k] = logp;
                  if (logp > maxLog) maxLog = logp;
                }

                // Convert to posterior
                const weights = new Array(K);
                let sumW = 0;
                for (let k = 0; k < K; k++) {
                  const w = Math.exp(logScores[k] - maxLog);
                  weights[k] = w;
                  sumW += w;
                }
                const posteriors = weights.map(w => w / sumW);

                // Build results table
                let rows = '';
                let bestIdx = 0;
                let bestPost = posteriors[0];
                for (let k = 0; k < K; k++) {
                  if (posteriors[k] > bestPost) {
                    bestPost = posteriors[k];
                    bestIdx = k;
                  }
                }

                for (let k = 0; k < K; k++) {
                  const highlight = k === bestIdx;
                  rows += `
                    <tr class="${highlight ? 'bg-blue-50' : ''}">
                      <td class="font-medium">${classNames[k]}</td>
                      <td>${priors[k].toFixed(4)}</td>
                      <td>${logScores[k].toFixed(4)}</td>
                      <td>${posteriors[k].toFixed(4)}${highlight ? ' <span class="text-[11px] text-blue-700 font-semibold">(max)</span>' : ''}</td>
                    </tr>
                  `;
                }
                resultsBody.innerHTML = rows;
                resultsContainer.classList.remove('hidden');

                // Interpretation
                const presentFeats = [];
                for (let j = 0; j < D; j++) {
                  if (obs[j] === 1) presentFeats.push(featureNames[j]);
                }
                const featStr = presentFeats.length
                  ? 'when the features ' + presentFeats.join(', ') + ' are present'
                  : 'when all features are absent';

                resultsInterpretation.textContent =
                  'Under the current naive Bayes model, the class with the highest posterior probability is "' +
                  classNames[bestIdx] + '" with P ≈ ' + (bestPost * 100).toFixed(2) +
                  '%. This is computed by combining the prior P(C) and the product of feature likelihoods P(x_j | C) ' +
                  featStr + '.';
              }

              btnClassify.addEventListener('click', classify);

              btnClearObs.addEventListener('click', () => {
                const chips = featureChipContainer.querySelectorAll('.nb-feature-chip');
                chips.forEach(btn => {
                  const stateSpan = btn.querySelector('.nb-chip-state');
                  btn.setAttribute('aria-pressed', 'false');
                  btn.classList.remove('nb-chip-active');
                  stateSpan.textContent = '(absent)';
                });
                nbHideError(resultError);
                resultsContainer.classList.add('hidden');
              });
            }());
          </script>

        </div>
      
<!-- AUDIT_SPINE_START -->
<hr class="auditspine-hr">
<section aria-label="Formulas, sources, changelog, verification">
  <span class="auditspine-badge">Audit: Complete</span>

  <details style="margin-top:10px">
    <summary><strong>Formula (LaTeX) + variables + units</strong></summary>
    <div class="auditspine-note" style="margin-top:10px">
      This section shows the formulas used by the calculator engine, plus variable definitions and units.
      
    </div>
    <div class="auditspine-formula">
      <div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[P(C_k \mid x) = \frac{P(C_k) P(x \mid C_k)}{P(x)}.\]</div>
  <pre class="auditspine-mono">P(C_k \mid x) = \frac{P(C_k) P(x \mid C_k)}{P(x)}.</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[P(C_k \mid x) \propto P(C_k) P(x \mid C_k).\]</div>
  <pre class="auditspine-mono">P(C_k \mid x) \propto P(C_k) P(x \mid C_k).</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[P(x \mid C_k) = P(x_1, \dots, x_d \mid C_k) \approx \prod_{j=1}^{d} P(x_j \mid C_k).\]</div>
  <pre class="auditspine-mono">P(x \mid C_k) = P(x_1, \dots, x_d \mid C_k) \approx \prod_{j=1}^{d} P(x_j \mid C_k).</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[\theta_{jk} = P(X_j = 1 \mid C_k),\]</div>
  <pre class="auditspine-mono">\theta_{jk} = P(X_j = 1 \mid C_k),</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[P(x_j \mid C_k) = \begin{cases} \theta_{jk}, &amp; \text{if } x_j = 1,\\[4pt] 1 - \theta_{jk}, &amp; \text{if } x_j = 0. \end{cases}\]</div>
  <pre class="auditspine-mono">P(x_j \mid C_k) = \begin{cases} \theta_{jk}, &amp; \text{if } x_j = 1,\\[4pt] 1 - \theta_{jk}, &amp; \text{if } x_j = 0. \end{cases}</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted LaTeX)</strong></div>
  <div style="margin-top:6px">\[s_k = \log P(C_k) + \sum_{j=1}^{d} \log P(x_j \mid C_k).\]</div>
  <pre class="auditspine-mono">s_k = \log P(C_k) + \sum_{j=1}^{d} \log P(x_j \mid C_k).</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted text)</strong></div>
  
  <pre class="auditspine-mono">\[ P(x \mid C_k) = P(x_1, \dots, x_d \mid C_k) \approx \prod_{j=1}^{d} P(x_j \mid C_k). \]</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted text)</strong></div>
  
  <pre class="auditspine-mono">\[ s_k = \log P(C_k) + \sum_{j=1}^{d} \log P(x_j \mid C_k). \]</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted text)</strong></div>
  
  <pre class="auditspine-mono">\[ \tilde p_k = \exp(s_k - s_{\max}), \quad P(C_k \mid x) = \frac{\tilde p_k}{\sum_{\ell=1}^{K} \tilde p_\ell}. \]</pre>
</div>
<div style="margin:10px 0">
  <div><strong>Formula (extracted text)</strong></div>
  
  <pre class="auditspine-mono">\[ \hat \theta_{jk} = \frac{n_{jk}^{(1)}}{n_k}. \]</pre>
</div>
      <div style="margin-top:12px"><strong>Variables and units</strong></div>
      <ul style="margin:8px 0 0 18px">
        <li><em>No variables provided in audit spec.</em></li>
      </ul>
    </div>
  </details>

  <div class="auditspine-note" style="margin-top:12px">
    <strong>Sources (authoritative):</strong>
    <ul style="margin:8px 0 0 18px">
      <li><strong>NIST — Weights and measures</strong> — nist.gov · Accessed 2026-01-19<br><a href="https://www.nist.gov/pml/weights-and-measures" target="_blank" rel="nofollow noopener">https://www.nist.gov/pml/weights-and-measures</a></li>
<li><strong>FTC — Consumer advice</strong> — consumer.ftc.gov · Accessed 2026-01-19<br><a href="https://consumer.ftc.gov/" target="_blank" rel="nofollow noopener">https://consumer.ftc.gov/</a></li>
    </ul>
  </div>

  <div class="auditspine-changelog" style="margin-top:12px">
    <strong>Changelog</strong><br>
    <div style="margin-top:6px">
      <strong>Version:</strong> 0.1.0-draft<br>
      <strong>Last code update:</strong> 2026-01-19
    </div>
    <div style="margin-top:10px">
  <strong>0.1.0-draft</strong> · 2026-01-19
  <ul style="margin:6px 0 0 18px">
    <li>Initial audit spec draft generated from HTML extraction (review required).</li>
<li>Verify formulas match the calculator engine and convert any text-only formulas to LaTeX.</li>
<li>Confirm sources are authoritative and relevant to the calculator methodology.</li>
  </ul>
</div>
  </div>

  <div class="auditspine-note" style="margin-top:12px">
    <strong>Verified by Ugo Candido on 2026-01-19</strong><br>
    <a href="https://calcdomain.com/ugocandido" target="_blank" rel="noopener">Profile</a> ·
    <a href="https://www.linkedin.com/in/ugocandido92821/" target="_blank" rel="noopener">LinkedIn</a>
  </div>
</section>
<!-- AUDIT_SPINE_END -->
</main>

      <aside class="w-full lg:w-1/3">
        <div class="space-y-6">

          <section aria-labelledby="related-ml" class="bg-white p-5 rounded-lg shadow-md">
            <h2 id="related-ml" class="text-lg font-semibold mb-3">Related statistics &amp; ML tools</h2>
            <ul class="space-y-2 text-sm">
              <li><a href="/bayes-theorem" class="text-blue-600 hover:underline">Bayes’ theorem calculator</a></li>
              <li><a href="/bayesian-inference" class="text-blue-600 hover:underline">Bayesian inference (binomial)</a></li>
              <li><a href="/binomial-distribution" class="text-blue-600 hover:underline">Binomial distribution</a></li>
              <li><a href="/normal-distribution" class="text-blue-600 hover:underline">Normal distribution</a></li>
              <li><a href="/z-score" class="text-blue-600 hover:underline">Z-score calculator</a></li>
              <li><a href="/regression-calculator" class="text-blue-600 hover:underline">Regression calculator</a></li>
              <li><a href="/pca" class="text-blue-600 hover:underline">Principal component analysis (PCA)</a></li>
              <li><a href="/cohen-s-kappa-calculator" class="text-blue-600 hover:underline">Cohen’s kappa</a></li>
              <li><a href="/classification-threshold" class="text-blue-600 hover:underline">Classification threshold (ROC) <span class="text-xs text-gray-400">(planned)</span></a></li>
            </ul>
          </section>

          <section class="bg-white p-5 rounded-lg shadow-md">
            <h2 class="text-lg font-semibold mb-3">Good practice for naive Bayes models</h2>
            <ul class="text-xs text-gray-700 space-y-1.5">
              <li>Inspect feature correlations: strong dependencies may lead to over-confident probabilities.</li>
              <li>Use Laplace or other smoothing when some features never appear in a class in training data.</li>
              <li>Evaluate performance with cross-validation or a held-out test set, not only on training data.</li>
              <li>Use naive Bayes as a simple, interpretable baseline alongside more complex models.</li>
              <li>For critical domains (medical, finance, safety), always combine models with expert review.</li>
            </ul>
          </section>

        </div>
      </aside>

    </div>
  </div>

  <footer class="bg-gray-900 text-white py-12">
  <div class="container mx-auto px-4">
    <div class="grid grid-cols-1 md:grid-cols-4 gap-8">
      <div>
        <h3 class="text-2xl font-bold mb-4">CalcDomain</h3>
        <p class="text-gray-400 mb-4">
          Your trusted source for free online calculators. Accurate, fast, and reliable calculations for every need.
        </p>
        </div>

      <div>
        <h4 class="text-lg font-semibold mb-4">Categories</h4>
                                                                        <ul class="space-y-2">
          <li><a href="https://calcdomain.com/categories/construction" class="text-gray-400 hover:text-white">Construction</a></li>
          <li><a href="https://calcdomain.com/categories/construction-diy" class="text-gray-400 hover:text-white">Construction & DIY</a></li>
          <li><a href="https://calcdomain.com/categories/engineering" class="text-gray-400 hover:text-white">Engineering</a></li>
          <li><a href="https://calcdomain.com/categories/finance" class="text-gray-400 hover:text-white">Finance</a></li>
          <li><a href="https://calcdomain.com/categories/general" class="text-gray-400 hover:text-white">General</a></li>
          <li><a href="https://calcdomain.com/categories/health-fitness" class="text-gray-400 hover:text-white">Health & Fitness</a></li>
          <li><a href="https://calcdomain.com/categories/lifestyle-everyday" class="text-gray-400 hover:text-white">Lifestyle & Everyday</a></li>
          <li><a href="https://calcdomain.com/categories/math" class="text-gray-400 hover:text-white">Math</a></li>
          <li><a href="https://calcdomain.com/categories/math-conversions" class="text-gray-400 hover:text-white">Math & Conversions</a></li>
          <li><a href="https://calcdomain.com/categories/science" class="text-gray-400 hover:text-white">Science</a></li>
        </ul>
      </div>

      <div>
        <h4 class="text-lg font-semibold mb-4">Popular Tools</h4>
        <ul class="space-y-2">
          <li><a href="https://calcdomain.com/mortgage-payment" class="text-gray-400 hover:text-white">Mortgage Calculator</a></li>
          <li><a href="https://calcdomain.com/percentage-calculator" class="text-gray-400 hover:text-white">Percentage Calculator</a></li>
          <li><a href="https://calcdomain.com/bmi-calculator" class="text-gray-400 hover:text-white">BMI Calculator</a></li>
          <li><a href="https://calcdomain.com/auto-loan-calculator" class="text-gray-400 hover:text-white">Auto Loan Calculator</a></li>
          <li><a href="https://calcdomain.com/house-affordability" class="text-gray-400 hover:text-white">House Affordability</a></li>
        </ul>
      </div>

      <div>
        <h4 class="text-lg font-semibold mb-4">Support</h4>
        <ul class="space-y-2">
          <li><a href="https://calcdomain.com/about" class="text-gray-400 hover:text-white">About Us</a></li>
          <li><a href="https://calcdomain.com/contact" class="text-gray-400 hover:text-white">Contact</a></li>
          <li><a href="https://calcdomain.com/privacy" class="text-gray-400 hover:text-white">Privacy Policy</a></li>
          <li><a href="https://calcdomain.com/terms" class="text-gray-400 hover:text-white">Terms of Service</a></li>
          <li><a href="https://calcdomain.com/sitemap.xml" class="text-gray-400 hover:text-white">Site Map</a></li>
        </ul>
      </div>
    </div>

    <div class="border-t border-gray-800 mt-8 pt-8 text-center text-gray-400">
      <p>&copy; 2025 CalcDomain. All Rights Reserved. | Free Online Calculators for Everyone</p>
    </div>
  </div>
</footer>











  <script src="/assets/js/script_menu.js" defer=""></script>
  <script src="/assets/js/script_faq.js" defer=""></script>
  <script src="search.js" defer=""></script>

  <script>
    window.MathJax = {
      tex: { inlineMath: [['\\(','\\)'], ['$', '$']], displayMath: [['$','$'], ['\\[','\\]']] },
      svg: { fontCache: 'global' }
    };
  </script>
  <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <script>
    // Mobile menu toggle
    (function () {
      const toggle = document.getElementById('mobile-menu-toggle');
      const menu = document.getElementById('mobile-menu');
      if (!toggle || !menu) return;
      toggle.addEventListener('click', () => {
        const isHidden = menu.classList.contains('hidden');
        menu.classList.toggle('hidden', !isHidden);
        toggle.setAttribute('aria-expanded', String(isHidden));
      });
    }());
  </script>



</body></html>